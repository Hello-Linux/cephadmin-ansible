# tasks file for cephadm config
---
- name: Init Ceph cluster use bootstrap node
  block:
    - name: Execute cephadm prepare-host command
      command: cephadm prepare-host
      register: cephadm_prepare_result

    - name: Assert that the cepdadm requirements was successful
      assert:
        that:
          - cephadm_prepare_result.rc == 0
        fail_msg: "cephadm is dependent on environment problems!"
        success_msg: "cephadm depends on the passing of the environment test!"

    - name: Bootstrap Ceph cluster with cephadm
      shell: cephadm bootstrap --mon-ip {{ ansible_host }} --allow-fqdn-hostname 2>&1 | tee -a /tmp/ceph_install.log && touch /tmp/success_bootstrap.txt
      args:
        warn: no
        creates: /tmp/success_bootstrap.txt

    - name: Copy public key to other nodes
      command: "ssh-copy-id -f -i /etc/ceph/ceph.pub -o StrictHostKeyChecking=no root@{{ item }}"
      with_items: "{{ groups['ceph_cluster'] }}"
      when:
        - inventory_hostname != item

    - name: Add hosts to Ceph cluster
      shell: cephadm shell -- ceph orch host add {{ item }} {{ hostvars[item]['ansible_host'] }}
      with_items: "{{ groups['ceph_cluster'] }}"
      when:
        - inventory_hostname != item
  when: deploy_role == 'main'

- name: Add user_defined labels to hosts
  command: cephadm shell -- ceph orch host label add {{ inventory_hostname }} {{ item }}
  loop: "{{ hostvars[inventory_hostname].label | from_yaml }}"
  when: hostvars[inventory_hostname].label is defined
  delegate_to: "{{ groups['ceph_cluster'][0] }}"

- name: Add OSD daemons
  command: cephadm shell -- ceph orch daemon add osd {{ inventory_hostname }}:data_devices={{ hostvars[inventory_hostname].osd_devices }}
  when:
    - hostvars[inventory_hostname].osd_devices is defined
  delegate_to: "{{ groups['ceph_cluster'][0] }}"

- name: Reschedule mon service
  command: cephadm shell -- ceph orch apply rgw myhammer '--placement=label:mon count-per-host:1'
  run_once: true
  delegate_to: "{{ groups['ceph_cluster'][0] }}"

- name: Apply RGW service
  command: cephadm shell -- ceph orch apply rgw {{ RGW_NAME }} '--placement=label:rgw count-per-host:1' --port={{ CEPH_RGW_PORT }}
  run_once: true
  delegate_to: "{{ groups['ceph_cluster'][0] }}"
  when:
    - ENABLE_RGW_SERVICE == "true"

- name: Apply CephFS service
  command: cephadm shell -- ceph fs volume create {{ CEPF_FS_NAME }} --placement=3
  run_once: true
  delegate_to: "{{ groups['ceph_cluster'][0] }}"
  when:
    - ENABLE_CEPHFS_SERVICE == "true"

- name: CephFS Export over NFS 
  block:
    - name: Apply CephFS service for nfs
      command: cephadm shell -- ceph mgr module enable nfs
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Create storage pools required by NFS
      command: cephadm shell -- ceph osd pool create {{ NFS_POOL_NAME }} {{ NFS_POOL_PG_NUMBER }} {{ NFS_POOL_PG_NUMBER }} replicated --autoscale-mode=on
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"
    
    - name: Enable the nfs application in the storage pool
      command: cephadm shell -- ceph osd pool application enable {{ NFS_POOL_NAME }} nfs
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Create new nfs cluster
      command: cephadm shell -- ceph nfs cluster create {{ NFS_CLUSTER_ID }} 3 --ingress --virtual_ip {{ NFS_CLUSTER_VIP }}
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Example Create an nfs export of CephFS
      command: cephadm shell -- ceph nfs export create cephfs --cluster-id {{ NFS_CLUSTER_ID }} --pseudo-path {{ NFS_PSEUDO_PATH }} --fsname {{ CEPF_FS_NAME }} --squash no_root_squash
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"
  when:
    - ENABLE_CEPHFS_SERVICE == "true"
    - ENABLE_CEPHFS_NFS_SERVICE == "true"

- name: Init userdefine rbd storage
  block:
    - name: Create storage pools required by rbd
      command: cephadm shell -- ceph osd pool create {{ RBD_POOL_NAME }} {{ RBD_PG_NUMBER }} {{ RBD_PG_NUMBER }} replicated --autoscale-mode=on
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Enable the rbd application in the storage pool
      command: cephadm shell -- ceph osd pool application enable {{ RBD_POOL_NAME }} rbd
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Start the rbd application in the storage pool
      command: cephadm shell -- rbd pool init {{ RBD_POOL_NAME }}
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Create the rbd device user in the storage pool
      command: cephadm shell -- ceph auth get-or-create client.{{ RBD_USER_NAME }} mon 'allow r' osd 'allow rwx pool={{ RBD_POOL_NAME }}'
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"

    - name: Create the rbd image in the storage pool
      command: cephadm shell -- rbd create --size {{ RBD_IMAGE_SIZE }} {{ RBD_POOL_NAME }}/{{ RBD_IMAGE_NAME }}
      run_once: true
      delegate_to: "{{ groups['ceph_cluster'][0] }}"
  when:
    - ENABLE_RDB_SERVICE == "true"
